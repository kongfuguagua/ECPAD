Brain-computer interfaces (BCI) represent one of the most dynamic areas of research in neural engineering, with significant potential for biomedical, neural rehabilitation, and intelligent robotics applications [1]. Specifically, motor-imagery electroencephalogram (MI-EEG) signals have shown promising results in providing a new control method for patients with motor disorders [2]. Despite the success of deep learning in analyzing MI-EEG, it is largely dependent on large-scale training datasets. MI-EEG signals are susceptible to a large number of artifacts such as eye movements, power line interference, electrooculogram (EOG)[3]. Furthermore, publicly available datasets are typically limited to laboratory settings, making it difficult to obtain large-scale datasets for real-world scenarios such as driving, flying, and sports, resulting in deep learning models unable to achieve high-precision classification. To address these challenges, transferring high signal-to-noise ratio datasets to the target domain and conducting deep learning with low signal-to-noise ratio datasets obtained in the target domain can effectively improve classification accuracy in the target domain [4].

Transfer learning is a highly active area of research in deep learning, offering the potential for unsupervised learning using unlabeled data. The transfer can take the form of features or classification models. Transfer Component Analysis (TCA) is a commonly used method for transferring features between domains. If a linear mapping exists that maps both domains to the same feature subspace with similar feature distributions [5], models trained in the source domain can be directly transferred to the target domain via linear transformation. Fine-tuning is a classic method for model transfer that involves retaining the shallow layers of a neural network trained in the source domain and training the deep layers on the target domain to complete the transfer [6]. When dealing with MI-EEG, TCA method has the disadvantage of transferring artifacts and features together to the target domain. Additionally, a substantial difference in distribution between the source and target domains makes it difficult to establish a linear transformation [7]. Fine-tuning requires a high-precision pre-training model, but existing models such as ResNet and VGG are trained in vastly different scenarios from MI tasks and thus cannot achieve effective transfer [8].

This paper proposed an adversarial mechanism based method for MI-EEG signal classification. The introduction of adversarial mechanisms enables the use of source domain strategies for target domain classification, resulting in high classification accuracy and generalization ability. Moreover, the method is unsupervised and therefore does not require any labeled data in the target domain. The model consists of a feature extractor, a domain discriminator, and a label classifier. The feature extractor extracts common features from the source and target domains, while the domain discriminator performs domain classification, and the label classifier performs classification. During the training process, the common features confuse the domain discriminator, causing an increase in domain loss. The domain discriminator optimizes towards the direction of minimum loss, resulting in an adversarial game between them.

We assessed the classification performance of our approach by utilizing datasets 2a and 2b from BCI competition IV [9][10], and compared it with the classification performance achieved by supervised learning, direct transfer, and fine-tuning methods. The findings indicate that our model attained significantly effective classification results in the target domain, which can be considered on par with the performance achieved by small-scale supervised learning.