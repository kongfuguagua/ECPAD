With the rapid development of smart manufacturing and flexible production, the flexibility of industrial production has been greatly enhanced [1], [2]. Industrial software needs to quickly redistribute and adjust production processes according to changes of orders, which has higher requirements for flexibility and scalability of industrial software [3], [4], [5]. Traditional industrial software adopts a monolithic service architecture. The high coupling and occupancy rate within the service will increase the complexity of the whole system. Its scalability, stability, and fault tolerance are difficult to meet the requirements of smart manufacturing. Therefore, the industrial software architecture based on microservices has been widely concerned [6], [7]. Through the microservice architecture, a complete service can be split into multiple loosely coupled microservices. Different microservices are logically independent and have a high degree of flexibility, scalability, and fault tolerance, which can well adapt to the requirements of smart manufacturing.

To meet the high requirements of computation-intensive tasks for real-time performance and service efficiency in smart manufacturing, edge computing-oriented microservice platforms are emerging [8], [9], [10], [11], [12]. At present, container technologies represented by Docker [13] and container orchestration tools represented by Kubernetes [14] are becoming mainstream solutions for microservice deployment and maintenance on edge platforms. According to different service requests and deployment strategies, each microservice which is packaged into a Docker image can be deployed to edge servers through container orchestration tools.

In the containerized deployment of microservices, service efficiency is an important indicator for evaluating the quality of the deployment solution. Service efficiency is mainly affected by two aspects. One is the startup time of microservices. It mainly depends on the pull delay of Docker images which are stored in the cloud through different image layers [15]. When a microservice needs to be provided locally, the edge server will pull a non-local container image containing all required layers from the cloud. Due to limited network bandwidth, image pulls incur a corresponding downlink delay. A comprehensive research shows that with a bandwidth of 100Mbps, the average startup time of a single image is about 20.7 seconds, while the average image pull delay is about 15.8 seconds, accounting for 76.6% of the average startup time [16]. Image pull delay has become a non-negligible factor affecting container startup time, which in turn affects the efficiency of service response. The other is the communication overhead between microservices. It depends on the amount of data communicated between microservices. An industrial application can be completed by multiple microservices deployed on one or more edge servers [17]. These microservices can be called microservice chains, and there will be frequent data exchanges between microservices in the same microservice chain [18]. A large amount of data transmission between microservices will cause high transmission delay, which will affect the service response efficiency.

Due to the above two aspects, it is very important to improve service efficiency through resource sharing. There are two types of resource sharing strategies for the improvement of service efficiency. One of the strategies for resource sharing is layer sharing [15]. Docker natively supports the sharing of layers. If the microservices deployed on the same edge server use the same image layer, the layer will not be pulled repeatedly when pulling images. This layer can be shared by all microservices on the server. The image pull delay can be effectively reduced by layer sharing, thereby improving the startup speed and service response efficiency of microservices. The other strategy for resource sharing is chain sharing [18], [19], which can be defined as the data sharing of microservices deployed on the same server. In the microservice chain, there is frequent data transfer between two adjacent microservices. If two microservices are deployed on the same server, the data can be directly accessed through chain sharing by the next microservice without multi-hop transmission of data. The delay and packet loss caused by data transmission can be reduced by chain sharing.

However, due to the limited resources of edge servers, it is impossible for all microservices to be deployed on the same edge server. Therefore, it is necessary to find an optimal microservice deployment strategy for the trade-off between layer sharing and chain sharing. Besides service efficiency, due to the limited resources of edge servers, the microservice deployment strategy can not make full use of different resources (such as computing and storage resources) at the same time, resulting in idle computing resources. Therefore, a method is also needed to reasonably allocate resources to different microservices deployed on a server and maximize the utilization of resources.

Aiming at resource sharing and maximizing resource utilization problems among microservices, the deployment of microservices mainly faces the following difficulties. 1) How to model the layered structure of the microservice image to accurately describe the relationship between the microservice image and the container layer. 2) How to describe the chain structure of microservices and the communication between microservices. 3) How to balance layer sharing and chain sharing to establish an optimization problem to achieve the best deployment strategy. 4) How to reallocate resources to microservices deployed on edge servers to make full use of computing resources. In this paper, we study the microservice deployment problem considering microservice layer sharing and chain sharing. The problem is modeled as an integer programming problem that minimizes image pull delay and communication overhead. Based on this problem, a microservice deployment strategy and resource redistribution scheme are proposed. The main contributions of this work are as follows:

We describe the layered structure and chain structure of microservices through the same model. An integer programming problem is established to minimize the image pull delay and communication overhead.

Through model reconstruction, we prove that the integer programming problem can be transformed into an integer quadratic programming problem with linear constraints. The optimal solution is obtained by using the successive convex approximation (SCA) method. This method can effectively balance the image pull delay and communication overhead.

A resource redistribution algorithm for edge servers is proposed to make full use of idle computing resources.

Through experiments, the results are evaluated in multiple dimensions, such as image pull delay and inter-service communication overhead. These experiments demonstrate the effectiveness of the proposed method.

The remainder of this paper is organized as follows. Section 2 briefly reviews the related literature. In Section 3, the layered structure and chain structure of the system are modeled, and the problem formulation is given. Section 4 solves the proposed problem. Section 5 proposes a resource redistribution algorithm for edge servers. Section 6 evaluates the results of the proposed method. Section 7 discusses the limitations and future work. Section 8 concludes the paper.